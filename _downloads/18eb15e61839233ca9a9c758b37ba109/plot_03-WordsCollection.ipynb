{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTutorial 03: Words Collection\n=============================\n\nCollecting literature data, extracting text and metadata for specified search terms.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Words Analysis\n--------------\n\nAnother way to scrape the literature is to collect text and meta-data from\nall papers found for a given set of terms.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lisc import Words\nfrom lisc.utils.db import SCDB\nfrom lisc.utils.io import save_object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Words Object\n------------\n\nThe 'Words' object is used to collection and analyzing text data and article metadata.\n\nSearch terms are specified to find papers of interest, from which text data and other\ninformation is collected.\n\nNote that the same approach for organizing search terms, including synonyms, inclusion\nand exclusion words, is used as for Counts, as described in the first tutorial.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up some terms\nterms = [['brain'], ['body']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize Words object and set the terms to search for\nwords = Words()\nwords.add_terms(terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Collect words data\nwords.run_collection(retmax='5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Words also saves the same list of Data objects\nprint(words.results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Word Collections\n----------------\n\nDepending on what the search terms are, collections of words papers can become quite large.\n\nBecause of this, you might want to use some of the available EUtils settings, and\nLISC options to help control how the data collection is done.\n\nIn the next example, we'll revisit the same search terms we used in the previous\n`Counts` analysis, and explore some of these settings.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up some terms\nterms = [['frontal lobe'], ['temporal lobe'], ['parietal lobe'], ['occipital lobe']]\nwords.add_terms(terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EUtils Settings\n~~~~~~~~~~~~~~~\n\nThe Pubmed EUtils has several settings that can help control searches, including:\n\n- `field` : which part of the record to search for search results\n- `retmax` : the maximum number of records to return for a given search\n- `usehistory` : whether to temporarily store results remotely and use them for interim requests\n\nAs some general guidelines, the `field` setting defaults to `TIAB` for titles and abstracts.\nThe `retmax` should be set to some upper bound if your search terms are likely to\nreturn a large number of papers. The `usehistory` parameter should be set to True if\nyou are running a large scrape, as this is more efficient.\n\nWord Collection Settings\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nIf you are collecting data for a large number of search terms, that may return a large\nnumber of papers, then the `Words` collection can take a while, and the amount of\ndata can become quite large.\n\nBecause of this, the `Words` object offers a setting of how / when to save data:\n\n- `save_and_clear` : whether to save out collected data and clear per term\n\nNow, let's run our bigger collection, using some of these settings.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up our database object, so we can save out data as we go\ndb = SCDB('lisc_db')\n\n# Collect words data\nwords.run_collection(usehistory=True, retmax='15', save_and_clear=True, directory=db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that at this point, our Words object does not actually include the collected data,\nsince we were saving and clearing the data out as we went.\n\nThe Words object does still however have all the information about the Term data, and we\ncan use that to help manage and reload our data, so it's worth saving as well.\n\nWe will analyze our words data in the next tutorial, so for now lets save out the Words object.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Save out the words data\nsave_object(words, 'tutorial_words', directory=db)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}