{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTutorial 02: Counts Analysis\n============================\n\nAnalyzing scraped co-occurence data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Counts Analyses\n---------------\n\nThis tutorial explores the built in utilities for exploring & analyzing counts data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lisc.utils.db import SCDB\nfrom lisc.utils.io import load_object\n\nfrom lisc.plts.counts import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Reload the counts object from the last tutorial\ncounts = load_object('tutorial_counts', SCDB('lisc_db'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Counts` object has some helper methods to explore the collected data.\n\nFirst lets check the number of counts per term list.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Look at the collect counts data for the first set of terms\ncounts.check_data(data_type='counts', dim='A')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Look at the collect counts data for the second set of terms\ncounts.check_data(data_type='counts', dim='B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normalization & Scores\n----------------------\n\nThe Counts co-occurence data collection gives us a raw data matrix of the number of\npapers in with terms co-occur, as well as counts of the number of total papers using\neach term.\n\nOnce we have this, we often will want to calculate either normalized co-occurence\nmeasures, and/or some kind of similarity score.\n\nTo normalize the data, we can divide the co-occurence counts by the number of papers\nper term. This allows us the examine and analyze, for example, the proportions of papers\nthat include particular co-occurence patterns.\n\nWe can also calculate some kind of association index or score. For example, the\n`Jaccard index <https://en.wikipedia.org/wiki/Jaccard_index>`_ is a standard meassure\nfor measuring the similarity of samples, and is also available to compute and use.\n\nWhen using the counts object, both of these measures are available, through the\n`compute_score` method. You can indicate which kind of score (normalization or association)\nindex) as an input to the method.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute a normalization of the co-occurence data\ncounts.compute_score('normalize', dim='A')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check out the computed normalization\nprint(counts.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The normalization is the number of papers with both terms, divided by the number of\npapers for each term alone. It can therefore be interpreted as a proportion of papers\nwith term `a` that also have term `b`, or as `a & b / a`.\n\nNote that when using two different terms lists, you have to choose which list of\nterms to normalize by. That is controlled by the 'dim' input.\n\nIn this case, we have calculated the number normalized data as the proportion of\npapers for each anatomical term that include each perception term.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute the association index\ncounts.compute_score('association')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check out the computed score\nprint(counts.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Jaccard index is a normalized measure of similarity, bounded between 0 and 1.\n\nOne benefit of the Jaccard index is that you do not have to choose a terms list\nto normalize by - the calulated measure considers both terms lists.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting and Clustering for Counts Data\n---------------------------------------\n\nCo-occurence data is basically a matrix of numbers reflecting the relationship between terms.\n\nLISC provides some plot function to visualize the co-occurence data, as a matrix.\n\nIn addition to plotting the data, we can also do clustering analysis and visualizations,\nthat attempt to find structure in the data. LISC also offers some common clustering\napproaches to sort and visualize collected co-occurence data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a matrix of the association index data\nplot_matrix(counts.score, counts.terms['B'].labels, counts.terms['A'].labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a clustermap of the association index data\nplot_clustermap(counts.score, counts.terms['B'].labels, counts.terms['A'].labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a dendrogram, to cluster the terms\nplot_dendrogram(counts.score, counts.terms['B'].labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}