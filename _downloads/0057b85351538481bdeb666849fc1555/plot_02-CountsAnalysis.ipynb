{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTutorial 02: Counts Analysis\n============================\n\nAnalyzing collected co-occurrence data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Counts Analyses\n---------------\n\nThis tutorial explores the built in utilities for exploring & analyzing counts data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lisc.utils.db import SCDB\nfrom lisc.utils.io import load_object\n\nfrom lisc.plts.counts import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Reload the counts object from the last tutorial\ncounts = load_object('tutorial_counts', SCDB('lisc_db'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :class:`~lisc.objects.Counts` object has some helper methods to explore the collected data.\n\nFirst lets check the number of counts per term list, which we can do with the\n:meth:`~lisc.objects.Counts.check_data` method.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Look at the collected counts data for the first set of terms\ncounts.check_data(data_type='counts', dim='A')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Look at the collected counts data for the second set of terms\ncounts.check_data(data_type='counts', dim='B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normalization & Scores\n----------------------\n\nThe Counts co-occurrence data collection gives us a raw data matrix of the number\nof articles in which terms co-occur, as well as the number of articles for each\nterm independently.\n\nOnce we have the co-occurrence matrix, we typically want to calculate a\nnormalized co-occurrence measure, and/or some other kind of similarity score.\n\nTo normalize the data, we can divide the co-occurrence counts by the number of articles\nper term. This allows us the examine, for example, the proportion of articles\nthat include particular co-occurrence patterns.\n\nWe can also calculate an association index or score. For example, the\n`Jaccard index <https://en.wikipedia.org/wiki/Jaccard_index>`_ is a standard measure\nfor measuring the similarity of samples, and is also available to compute and use.\n\nWith the counts object, both of these measures are available, using the\n:meth:`~lisc.objects.Counts.compute_score` method. You can indicate which kind of score\n- normalization or association index - as an input to the method.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute a normalization of the co-occurrence data\ncounts.compute_score('normalize', dim='A')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check out the computed normalization\nprint(counts.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The normalization is the number of articles with both terms, divided by the number of\narticles for each term alone. It can therefore be interpreted as a proportion of articles\nwith term `a` that also have term `b`, or as `a & b / a`.\n\nNote that when using two different terms lists, you have to choose which list of\nterms to normalize by. That is controlled by the 'dim' input.\n\nIn this case, we have calculated the normalized data as the proportion of\narticles for each anatomical term that include each perception term.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute the association index\ncounts.compute_score('association')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check out the computed score\nprint(counts.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Jaccard index is a normalized measure of similarity, bounded between 0 and 1.\n\nOne benefit of the Jaccard index is that you do not have to choose a terms list\nto normalize by - the calculated measure considers both terms lists.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting and Clustering for Counts Data\n---------------------------------------\n\nCo-occurrence data is basically a matrix of numbers reflecting the relationship between terms.\n\nLISC provides some plot functions to visualize the co-occurrence data, as a matrix.\n\nIn addition to plotting the data, we can also do clustering analysis and visualizations,\nthat attempt to find structure in the data.\n\nLISC also offers some common clustering approaches to sort and visualize\ncollected co-occurrence data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a matrix of the association index data\nplot_matrix(counts.score, counts.terms['B'].labels, counts.terms['A'].labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a clustermap of the association index data\nplot_clustermap(counts.score, counts.terms['B'].labels, counts.terms['A'].labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a dendrogram, to cluster the terms\nplot_dendrogram(counts.score, counts.terms['B'].labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}