<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Tutorial 01 - Counts Scraping &#8212; lisc 0.1.0-dev documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          lisc</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1.0-dev</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../api.html">API</a></li>
                <li><a href="index.html">Tutorial</a></li>
                <li><a href="https://github.com/lisc-tools/lisc">GitHub</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Tutorial 01 - Counts Scraping</a><ul>
<li><a class="reference internal" href="#lisc">LISC</a></li>
<li><a class="reference internal" href="#counts">Counts</a></li>
<li><a class="reference internal" href="#id1">Counts</a></li>
<li><a class="reference internal" href="#count-object">Count Object</a></li>
<li><a class="reference internal" href="#synonyms-exclusion-words">Synonyms &amp; Exclusion Words</a></li>
<li><a class="reference internal" href="#words">Words</a></li>
<li><a class="reference internal" href="#metadata">Metadata</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/auto_tutorial/tutorial01-CountsScraping.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-auto-tutorial-tutorial01-countsscraping-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="tutorial-01-counts-scraping">
<span id="sphx-glr-auto-tutorial-tutorial01-countsscraping-py"></span><h1>Tutorial 01 - Counts Scraping<a class="headerlink" href="#tutorial-01-counts-scraping" title="Permalink to this headline">¶</a></h1>
<div class="section" id="lisc">
<h2>LISC<a class="headerlink" href="#lisc" title="Permalink to this headline">¶</a></h2>
<p>LIterature SCanner (LISC) is a python module for scraping literature data. It is basically a wrapper around the Pubmed [E-Utilities](<a class="reference external" href="https://www.ncbi.nlm.nih.gov/books/NBK25501/">https://www.ncbi.nlm.nih.gov/books/NBK25501/</a>).</p>
<p>LISC provides for two different ‘types’ of scraping, ‘Counts’ and ‘Words’.</p>
</div>
<div class="section" id="counts">
<h2>Counts<a class="headerlink" href="#counts" title="Permalink to this headline">¶</a></h2>
<p>‘Counts’ scrapes for co-occurence of given set(s) of terms.</p>
<p>Words</p>
<p>‘Words’ scrapes abstract text data, and paper meta-data, for all papers found for a given set of terms.</p>
<p>Functions vs. Objects</p>
<p>Each of these types of scrapes can be called in one of two ways, either by using scrape functions provided by LISC (function approach), or by using objects provided by LISC (OOP approach).</p>
<p>Note that, under the hood, these methods are the same, the OOP oriented approach simply provides wrappers around the scraping functions.</p>
<dl class="docutils">
<dt>Add lisc to path - assumes lisc is available one step up in the directory</dt>
<dd>This should work if cloned from Github</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<dl class="docutils">
<dt>Set up some test data</dt>
<dd>Note that each entry is itself a list</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">terms_a</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;brain&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;cognition&#39;</span><span class="p">]]</span>
<span class="n">terms_b</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;body&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;biology&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;disease&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="section" id="id1">
<h2>Counts<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>‘Counts’ scraping gets data about the co-occurence of terms of interest.</p>
<p>Specifically, it search titles and abstracts, and checks how often two terms of interest appear together in the literature.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import LISC - Count</span>
<span class="kn">from</span> <span class="nn">lisc.count</span> <span class="kn">import</span> <span class="n">Count</span>
<span class="kn">from</span> <span class="nn">lisc.scrape</span> <span class="kn">import</span> <span class="n">scrape_counts</span>
</pre></div>
</div>
<p>scrape_counts function</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run a scrape of &#39;counts&#39; (co-occurence data) - across a single list of terms</span>
<span class="n">dat_numbers</span><span class="p">,</span> <span class="n">dat_percent</span><span class="p">,</span> <span class="n">term_counts</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">meta_dat</span> <span class="o">=</span> <span class="n">scrape_counts</span><span class="p">(</span><span class="n">terms_a</span><span class="p">,</span> <span class="n">db</span><span class="o">=</span><span class="s1">&#39;pubmed&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Check out how many papers where found for each combination</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">dat_numbers</span><span class="p">)</span>
</pre></div>
</div>
<p>Check out the percent of paper overlap</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">dat_percent</span><span class="p">)</span>
</pre></div>
</div>
<p>Print out many papers found for each term</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">term</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">terms_a</span><span class="p">,</span> <span class="n">term_counts</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{:12} : {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">count</span><span class="p">))</span>
</pre></div>
</div>
<p>When given a single set of terms, the ‘Counts’ scrapes each term  against each other term.</p>
<p>You can also specify different sets of terms to scrape, as below, whereby each term in list A is scraped for co-occurence for each term in list B (but not to other terms in list A).</p>
<p>Run a scrape of ‘counts’ (co-occurence data) across two different lists of terms</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dat_numbers</span><span class="p">,</span> <span class="n">dat_percent</span><span class="p">,</span> <span class="n">term_counts_a</span><span class="p">,</span> <span class="n">term_counts_b</span><span class="p">,</span> <span class="n">meta_dat</span> <span class="o">=</span> <span class="n">scrape_counts</span><span class="p">(</span>
    <span class="n">terms_lst_a</span><span class="o">=</span><span class="n">terms_a</span><span class="p">,</span> <span class="n">terms_lst_b</span><span class="o">=</span><span class="n">terms_b</span><span class="p">,</span> <span class="n">db</span><span class="o">=</span><span class="s1">&#39;pubmed&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="count-object">
<h2>Count Object<a class="headerlink" href="#count-object" title="Permalink to this headline">¶</a></h2>
<p>There is also an OOP interface available in LISC, to organize the terms and data, and run scrapes.</p>
<p>Note that the underlying code is the same - the count object ultimately calls the same scrape function as above.</p>
<p>Initialize counts object</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span> <span class="o">=</span> <span class="n">Count</span><span class="p">()</span>
</pre></div>
</div>
<p>Set terms to run</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="o">.</span><span class="n">set_terms</span><span class="p">(</span><span class="n">terms_a</span><span class="p">)</span>
</pre></div>
</div>
<p>Run scrape</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="o">.</span><span class="n">run_scrape</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The Counts object also comes with some helper methods to check out the data.</p>
<p>Check the highest associations for each term</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="o">.</span><span class="n">check_cooc</span><span class="p">()</span>
</pre></div>
</div>
<p>Check how many papers were found for each search term</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="o">.</span><span class="n">check_counts</span><span class="p">()</span>
</pre></div>
</div>
<p>Check the top term</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="o">.</span><span class="n">check_top</span><span class="p">()</span>
</pre></div>
</div>
<p>Co-occurence data - different word lists</p>
<p>Initialize count object</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts_two</span> <span class="o">=</span> <span class="n">Count</span><span class="p">()</span>
</pre></div>
</div>
<dl class="docutils">
<dt>Set terms lists</dt>
<dd>Different terms lists are indexed by the ‘A’ and ‘B’ labels</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts_two</span><span class="o">.</span><span class="n">set_terms</span><span class="p">(</span><span class="n">terms_a</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="n">counts_two</span><span class="o">.</span><span class="n">set_terms</span><span class="p">(</span><span class="n">terms_b</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Scrape co-occurence data</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts_two</span><span class="o">.</span><span class="n">run_scrape</span><span class="p">()</span>
</pre></div>
</div>
<dl class="docutils">
<dt>From there you can use all the same methods to explore the data</dt>
<dd>You can also specify which list to check</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts_two</span><span class="o">.</span><span class="n">check_cooc</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">counts_two</span><span class="o">.</span><span class="n">check_cooc</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="synonyms-exclusion-words">
<h2>Synonyms &amp; Exclusion Words<a class="headerlink" href="#synonyms-exclusion-words" title="Permalink to this headline">¶</a></h2>
<p>There is also support for adding synonyms and exclusion words.</p>
<p>Synonyms are combined with the ‘OR’ operator, meaning results will be returned if they include any of the given terms.</p>
<p>Exclusion words are combined with the ‘NOT’ operator, meaning entries will be excluded if they include these terms.</p>
<p>For example, a using search terms [‘gene’, ‘genetic’] with exclusion words [‘protein’] creates the search:
- (“gene”OR”genetic”NOT”protein”)</p>
<p>Initialize Count object</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span> <span class="o">=</span> <span class="n">Count</span><span class="p">()</span>
</pre></div>
</div>
<dl class="docutils">
<dt>Set up terms with synonyms</dt>
<dd>Being able to include synonyms is the reason each term entry is itself a list</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">terms_lst</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;gene&#39;</span><span class="p">,</span> <span class="s1">&#39;genetic&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;cortex&#39;</span><span class="p">,</span> <span class="s1">&#39;cortical&#39;</span><span class="p">]]</span>

<span class="c1"># Set up exclusions</span>
<span class="c1">#  You can also include synonyms for exclusions - which is why each entry is also a list</span>
<span class="n">excl_lst</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;protein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;subcortical&#39;</span><span class="p">]]</span>

<span class="c1"># Set the terms &amp; exclusions</span>
<span class="n">counts</span><span class="o">.</span><span class="n">set_terms</span><span class="p">(</span><span class="n">terms_lst</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="n">counts</span><span class="o">.</span><span class="n">set_exclusions</span><span class="p">(</span><span class="n">excl_lst</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can check which terms are loaded</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="o">.</span><span class="n">terms</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">check_terms</span><span class="p">()</span>
</pre></div>
</div>
<p>Check exclusion words</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="o">.</span><span class="n">terms</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">check_exclusions</span><span class="p">()</span>
</pre></div>
</div>
<p>LISC objects will use the first item of each terms lists as a label for that term</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">counts</span><span class="o">.</span><span class="n">terms</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">labels</span>
</pre></div>
</div>
<p>Note that searching across different terms lists, and using synonyms and exclusions can all also be done directly using the scrape_counts function.</p>
</div>
<div class="section" id="words">
<h2>Words<a class="headerlink" href="#words" title="Permalink to this headline">¶</a></h2>
<p>Another way to scrape the data is to get some paper data from</p>
<p>Import LISC - Words</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lisc.words</span> <span class="kn">import</span> <span class="n">Words</span>
<span class="kn">from</span> <span class="nn">lisc.scrape</span> <span class="kn">import</span> <span class="n">scrape_words</span>
</pre></div>
</div>
<p>scrape_words function</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Scrape words data</span>
<span class="c1">#  Set the scrape to return data for at most 5 papers per term</span>
<span class="n">dat</span><span class="p">,</span> <span class="n">meta_dat</span> <span class="o">=</span> <span class="n">scrape_words</span><span class="p">(</span><span class="n">terms_a</span><span class="p">,</span> <span class="n">retmax</span><span class="o">=</span><span class="s1">&#39;5&#39;</span><span class="p">,</span> <span class="n">use_hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">save_n_clear</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The function returns a list of LISC Data objects</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dat</span>
</pre></div>
</div>
<p>Each data object holds the data for the scraped papers</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d1</span> <span class="o">=</span> <span class="n">dat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Print out some of the data</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">d1</span><span class="o">.</span><span class="n">n_articles</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">d1</span><span class="o">.</span><span class="n">titles</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Words Object</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize Words object</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">Words</span><span class="p">()</span>
</pre></div>
</div>
<p>Set terms to search</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">words</span><span class="o">.</span><span class="n">set_terms</span><span class="p">(</span><span class="n">terms_a</span><span class="p">)</span>
</pre></div>
</div>
<p>Run words scrape</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">words</span><span class="o">.</span><span class="n">run_scrape</span><span class="p">(</span><span class="n">retmax</span><span class="o">=</span><span class="s1">&#39;5&#39;</span><span class="p">,</span> <span class="n">save_n_clear</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Words also saves the same list of Data objects</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">words</span><span class="o">.</span><span class="n">results</span>

<span class="c1"># The use of synonyms and exclusion words, demonstrated above for counts, applies in the same way to the scraping words.</span>
</pre></div>
</div>
<p>Exploring Words Data</p>
<p>The words object also has a couple convenience methods for exploring the data.</p>
<p>Indexing with labels</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="s1">&#39;brain&#39;</span><span class="p">])</span>
</pre></div>
</div>
<dl class="docutils">
<dt>Iterating through papers found from a particular search term</dt>
<dd>The iteration returns a dictionary with all the paper data</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">art</span> <span class="ow">in</span> <span class="n">words</span><span class="p">[</span><span class="s1">&#39;cognition&#39;</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">art</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="metadata">
<h2>Metadata<a class="headerlink" href="#metadata" title="Permalink to this headline">¶</a></h2>
<p>Regardless of what you are scraping, or how you run it through LISC, there is some meta-data saved.</p>
<p>This data is collected in a dictionary, that is returned by the scrape functions (and saved to the objects, if applicable).</p>
<p>The meta data includes some information on the database that was scraped</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">meta_dat</span><span class="p">[</span><span class="s1">&#39;db_info&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># It also includes the Requester object, used to launch URL requests, which also has some details about the scrape</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Start time:    &#39;</span><span class="p">,</span> <span class="n">meta_dat</span><span class="p">[</span><span class="s1">&#39;req&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">st_time</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;End time:      &#39;</span><span class="p">,</span> <span class="n">meta_dat</span><span class="p">[</span><span class="s1">&#39;req&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">en_time</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;# of requests: &#39;</span><span class="p">,</span> <span class="n">meta_dat</span><span class="p">[</span><span class="s1">&#39;req&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">n_requests</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorial-tutorial01-countsscraping-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/fd2024828217f06c919a21982c77ee52/tutorial01-CountsScraping.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial01-CountsScraping.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/ec515fd4435b91d7fd1c4257f568b0e4/tutorial01-CountsScraping.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial01-CountsScraping.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2018, Thomas Donoghue.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>