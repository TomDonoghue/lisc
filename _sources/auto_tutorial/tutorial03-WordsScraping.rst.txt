.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_tutorial_tutorial03-WordsScraping.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_tutorial03-WordsScraping.py:


Tutorial 03 - Words Scraping
============================


Words
-----

Another way to scrape the data is to get some paper data from


Import LISC - Words



.. code-block:: python

    from lisc.words import Words
    from lisc.scrape import scrape_words


Set up some test data
 Note that each entry should be a list



.. code-block:: python

    terms_a = [['brain'], ['cognition']]
    terms_b = [['body'], ['biology'], ['disease']]


Function Approach: scrape_words

Scrape words data - set the scrape to return data for at most 5 papers per term



.. code-block:: python

    dat, meta_dat = scrape_words(terms_a, retmax='5', use_hist=False, save_n_clear=False, verbose=True)


The function returns a list of LISC Data objects



.. code-block:: python

    dat



.. code-block:: python

    meta_dat['req'].n_requests

    # Each data object holds the data for the scraped papers
    d1 = dat[0]

    # Print out some of the data
    print(d1.n_articles, '\n')
    print('\n'.join(d1.titles), '\n')



Object Approach: Words
----------------------



.. code-block:: python


    # Initialize Words object
    words = Words()

    # Set terms to search
    words.set_terms(terms_a)

    # Run words scrape
    words.run_scrape(retmax='5', save_n_clear=False)



Words also saves the same list of Data objects



.. code-block:: python

    words.results


    # The use of synonyms and exclusion words, demonstrated above for counts, applies in the same way to the scraping words.


Exploring Words Data
--------------------

The words object also has a couple convenience methods for exploring the data.



.. code-block:: python



    # Indexing with labels
    print(words['brain'])



Iterating through papers found from a particular search term
 The iteration returns a dictionary with all the paper data



.. code-block:: python

    for art in words['cognition']:
        print(art['title'])


Metadata
--------

Regardless of what you are scraping, or how you run it through LISC, there is some meta-data saved.

This data is collected in a dictionary, that is returned by the scrape functions (and saved to the objects, if applicable).


The meta data includes some information on the database that was scraped



.. code-block:: python

    meta_dat['db_info']
    #
    # This data is also saved to object
    words.meta_dat['db_info']


It also includes the Requester object, which is used to launch URL requests
  This object also stores some details about the scrape
  It can be used, for example, to track how long scrapes take, and how many requests they include



.. code-block:: python

    print('Start time:    ', meta_dat['req'].st_time)
    print('End time:      ', meta_dat['req'].en_time)
    print('# of requests: ', meta_dat['req'].n_requests)


**Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_auto_tutorial_tutorial03-WordsScraping.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: tutorial03-WordsScraping.py <tutorial03-WordsScraping.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: tutorial03-WordsScraping.ipynb <tutorial03-WordsScraping.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
