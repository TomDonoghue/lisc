.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_tutorials_plot_02-CountsAnalysis.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_plot_02-CountsAnalysis.py:


Tutorial 02: Counts Analysis
============================

Analyzing collected co-occurrence data.


Counts Analyses
---------------

This tutorial explores the built in utilities for exploring & analyzing counts data.




.. code-block:: python


    from lisc.utils.db import SCDB
    from lisc.utils.io import load_object

    from lisc.plts.counts import *








.. code-block:: python


    # Reload the counts object from the last tutorial
    counts = load_object('tutorial_counts', SCDB('lisc_db'))







The `Counts` object has some helper methods to explore the collected data.

First lets check the number of counts per term list.




.. code-block:: python


    # Look at the collected counts data for the first set of terms
    counts.check_data(data_type='counts', dim='A')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    For  'frontal lobe'    the highest association is  'audition'        with         378
    For  'temporal lobe'   the highest association is  'audition'        with        1300
    For  'parietal lobe'   the highest association is  'audition'        with         231
    For  'occipital lobe'  the highest association is  'vision'          with         236



.. code-block:: python


    # Look at the collected counts data for the second set of terms
    counts.check_data(data_type='counts', dim='B')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    For  'vision'          the highest association is  'occipital lobe'  with         236
    For  'audition'        the highest association is  'temporal lobe'   with        1300
    For  'somatosensory'   the highest association is  'parietal lobe'   with         187
    For  'olfaction'       the highest association is  'temporal lobe'   with          71
    For  'gustation'       the highest association is  'temporal lobe'   with          44
    For  'proprioception'  the highest association is  'parietal lobe'   with           9
    For  'nociception'     the highest association is  'temporal lobe'   with         199


Normalization & Scores
----------------------

The Counts co-occurrence data collection gives us a raw data matrix of the number of
articles in which terms co-occur, as well as the number of articles for each term independently.

Once we have the co-occurence matrix, we typically want to calculate a
normalized co-occurrence measure, and/or some other kind of similarity score.

To normalize the data, we can divide the co-occurrence counts by the number of articles
per term. This allows us the examine, for example, the proportion of articles
that include particular co-occurrence patterns.

We can also calculate an association index or score. For example, the
`Jaccard index <https://en.wikipedia.org/wiki/Jaccard_index>`_ is a standard meassure
for measuring the similarity of samples, and is also available to compute and use.

With the counts object, both of these measures are available, using the
`compute_score` method. You can indicate which kind of score - normalization or
association index - as an input to the method.




.. code-block:: python


    # Compute a normalization of the co-occurrence data
    counts.compute_score('normalize', dim='A')








.. code-block:: python


    # Check out the computed normalization
    print(counts.score)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [[1.05895821e-02 2.70463652e-02 9.58786491e-03 3.57756153e-03
      1.14481969e-03 2.86204923e-04 1.14481969e-02]
     [6.87590108e-03 4.80573731e-02 6.80196666e-03 2.62467192e-03
      1.62655724e-03 7.39344202e-05 7.35647481e-03]
     [1.75656127e-02 4.77371358e-02 3.86443480e-02 1.65323414e-03
      1.23992560e-03 1.85988841e-03 2.33519322e-02]
     [6.43929059e-02 2.31923602e-02 9.54979536e-03 1.36425648e-03
      0.00000000e+00 0.00000000e+00 1.71896317e-02]]


The normalization is the number of articles with both terms, divided by the number of
articles for each term alone. It can therefore be interpreted as a proportion of articles
with term `a` that also have term `b`, or as `a & b / a`.

Note that when using two different terms lists, you have to choose which list of
terms to normalize by. That is controlled by the 'dim' input.

In this case, we have calculated the normalized data as the proportion of
articles for each anatomical term that include each perception term.




.. code-block:: python


    # Compute the association index
    counts.compute_score('association')








.. code-block:: python


    # Check out the computed score
    print(counts.score)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [[1.16267195e-03 3.37985855e-03 3.14960630e-03 1.86720442e-03
      3.76896259e-04 2.14258932e-04 2.63222835e-04]
     [1.32544716e-03 1.04845474e-02 3.31113910e-03 1.78248644e-03
      7.92807078e-04 6.30000630e-05 3.20509723e-04]
     [7.19004559e-04 2.24601114e-03 5.60635587e-03 4.52411921e-04
      1.80045011e-04 9.44683531e-04 1.88723362e-04]
     [2.01892313e-03 8.34798323e-04 1.08248539e-03 3.02810078e-04
      0.00000000e+00 0.00000000e+00 1.05415336e-04]]


The Jaccard index is a normalized measure of similarity, bounded between 0 and 1.

One benefit of the Jaccard index is that you do not have to choose a terms list
to normalize by - the calculated measure considers both terms lists.



Plotting and Clustering for Counts Data
---------------------------------------

Co-occurrence data is basically a matrix of numbers reflecting the relationship between terms.

LISC provides some plot functions to visualize the co-occurrence data, as a matrix.

In addition to plotting the data, we can also do clustering analysis and visualizations,
that attempt to find structure in the data.

LISC also offers some common clustering approaches to sort and visualize
collected co-occurrence data.




.. code-block:: python


    # Plot a matrix of the association index data
    plot_matrix(counts.score, counts.terms['B'].labels, counts.terms['A'].labels)




.. image:: /auto_tutorials/images/sphx_glr_plot_02-CountsAnalysis_001.png
    :class: sphx-glr-single-img





.. code-block:: python


    # Plot a clustermap of the association index data
    plot_clustermap(counts.score, counts.terms['B'].labels, counts.terms['A'].labels)




.. image:: /auto_tutorials/images/sphx_glr_plot_02-CountsAnalysis_002.png
    :class: sphx-glr-single-img





.. code-block:: python


    # Plot a dendrogram, to cluster the terms
    plot_dendrogram(counts.score, counts.terms['B'].labels)



.. image:: /auto_tutorials/images/sphx_glr_plot_02-CountsAnalysis_003.png
    :class: sphx-glr-single-img




**Total running time of the script:** ( 0 minutes  0.526 seconds)


.. _sphx_glr_download_auto_tutorials_plot_02-CountsAnalysis.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_02-CountsAnalysis.py <plot_02-CountsAnalysis.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_02-CountsAnalysis.ipynb <plot_02-CountsAnalysis.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
